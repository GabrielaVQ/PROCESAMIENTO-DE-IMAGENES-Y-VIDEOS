{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Comando para instalar OpenCv\n",
    "#!pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # Se importa la libería para OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nothing(x): #Función auxiliar para la creación del trackbar\n",
    "    pass\n",
    "\n",
    "#cap = cv2.VideoCapture(0,cv2.CAP_DSHOW) #Comando usado para capturar los frames de la cámara\n",
    "cap = cv2.VideoCapture('video1.mp4') #Para capturar un video\n",
    "\n",
    "#Se indica el nombre del video a guardar y sus caracteristicas\n",
    "salida = cv2.VideoWriter('vs1.mp4',cv2.VideoWriter_fourcc(*'XVID'),30,(854,480))#fps, (ancho de frame, alto de frame)\n",
    "\n",
    "faceClassif = cv2.CascadeClassifier('haarcascade_frontalface.xml') #Se carga el clasificador\n",
    "\n",
    "cv2.namedWindow('DIFUMINACION') #Nombre de la ventana a visualizar el video\n",
    "cv2.createTrackbar('Blur','DIFUMINACION',8,20,nothing) #Se crea el trackbar\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret,frame = cap.read()    #Lee frame del video\n",
    "    \n",
    "    if ret==False: #Si el video finaliza, se rompe el ciclo\n",
    "        break\n",
    "        \n",
    "    val = cv2.getTrackbarPos('Blur','DIFUMINACION') #Obtiene el valor de la posición de la perilla del trackbar\n",
    "\n",
    "    faces = faceClassif.detectMultiScale(frame, 1.05, 5)#Se almacena rostro identificado con Haarcascade\n",
    "\n",
    "    for (x,y,w,h) in faces: #Matriz de rostro identificado\n",
    "        if val > 0: #Si se aplica difuminación\n",
    "            frame[y:y+h,x:x+w] = cv2.blur(frame[y:y+h,x:x+w],(val,val))#Se aplica difuminación al rostro, según posición de perilla (val)\n",
    "    cv2.imshow('DIFUMINACION',frame)#Muestra el frame con o sin difuminacion aplicada\n",
    "    \n",
    "    salida.write(frame)#Insertar frame al video de salida\n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xFF #Guarda la tecla pulsada\n",
    "    if k == 27: #Si es la tecla Esc se rompe el ciclo\n",
    "        break\n",
    "        \n",
    "        \n",
    "cap.release()#Cerrar el video que se estaba leyendo\n",
    "\n",
    "salida.release() # cerrar el video que se esta guardando\n",
    "\n",
    "cv2.destroyAllWindows()#cerrar todas las ventanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
